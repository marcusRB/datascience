{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic: Machine Learning from Disaster\n",
    "**Predict survival on the Titanic**\n",
    "<hr>\n",
    "I barely remember first when exactly I watched Titanic movie but still now Titanic remains a discussion subject in the most diverse areas. The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. It was April 15-1912 during her maiden voyage, the Titanic sank after colliding with an iceberg and killing 1502 out of 2224 passengers and crew. \n",
    "\n",
    "In this kaggle challenge, we're asked to complete the analysis of what sorts of people were likely to survive. In particular, we're asked to apply the tools of **machine learning** to predict which passengers survived the tragedy.\n",
    "\n",
    "More challenge information and datasets are available on [Kaagle Titanic Page](https://www.kaggle.com/c/titanic/data) The datasets has been split into two groups:\n",
    "\n",
    "- training set (train.csv)\n",
    "- test set (test.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Big Picture <a class=\"anchor\" id=\"4-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "The goal is to build a Model that can predict the survival or the death of a given passenger based on a set of variables describing their such as age, sex, or passenger class on the boat.\n",
    "\n",
    "### Frame the Problem\n",
    "\n",
    "To frame the problem elegantly, is very much important because it will determine our problem spaces. What algorithms we will select, what performance measure we will use to evaluate our model and also how much effort we should spend tweaking it. \n",
    "\n",
    "The test set should be used to see how well our model performs on unseen data. For the test set, the ground truth for each passenger is not provided. It is our job to predict these outcomes. For each passenger in the test set, we use the trained model to predict whether or not they survived the sinking of the Titanic. We will use **Cross-validation** for evaluating estimator performance.\n",
    "\n",
    "Basically, we've two datasets are available, a `train set` and a `test set`. We'll be using the training set to build our predictive model and the testing set will be used to validate that model. This is a binary classification problem. \n",
    "\n",
    "To solve this **ML** problem, topics like feature analysis, data visualization, missing data imputation, feature engineering, model fine tuning and various classification models will be addressed for ensemble modeling.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "In Data Science or ML problem spaces, Data Preprocessing means a lot, which is to make the Data usable or clean before using it, like before fit the model.\n",
    "\n",
    "Now, the real world data is so messy, like following -\n",
    "* **inconsistant values**\n",
    "* **duplicate records**\n",
    "* **missing values**\n",
    "* **invalid data**\n",
    "* **outlier**\n",
    "\n",
    "So what? Actually this is a matter of big concern. Because, Model can't handle missing data. So, we need to handle this manually. Actually there're many approaches we can take to handle missing value in our data sets, such as-\n",
    "\n",
    "* **Remove observation/records that have missing values.** But..\n",
    "  - data may randomly missing, so by doing this we may loss a lots of data\n",
    "  - data may non-randomly missing, so by doing this we may also loss a lots of data, again we're also    introducing potential biases \n",
    "  \n",
    "* **Imputation**\n",
    "  - replace missing values with another values \n",
    "  - strategies: mean, median or highest frequency value of the given feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "<hr>\n",
    "The steps we will go through:\n",
    "\n",
    "[Get The Data](#2-bullet)\n",
    "\n",
    "Here we explore what inside of the dataset and make our first commit on it.\n",
    "    \n",
    "[Feature Analysis To Gain Insights](#5-bullet)\n",
    "\n",
    "First we try to find out outlier from our datasets. There're many method to dectect outlier but here we will use tukey method to detect it. Then we will do component analysis of our features.\n",
    "\n",
    "[Feature Engineering](#9-bullet)\n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. And here, in our datasets there are few features that we can do engineering on it. I like to choose two of them.\n",
    "    - Name\n",
    "    - Family Size\n",
    "    \n",
    "[Predictive Modeling](#10-bullet)\n",
    "\n",
    "Here, we will use various classificatiom models and compare the results. We'll use Cross-validation for evaluating estimator performance and fine-tune the model and observe the learning curve, of best estimator and finally, will do enseble modeling of with three best predictive model. \n",
    "\n",
    "[Submit Predictor](#11-bullet)\n",
    "\n",
    "Create a CSV file and submit to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import <a class=\"anchor\" id=\"1-bullet\"></a>\n",
    "<hr>\n",
    "At first we will load some various libraries. At first sight it may be confusing but we will see the use cases each of them in details later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing and Visualization Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "#  Data Modelling Libraries\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\n",
    "                             VotingClassifier)\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV, cross_val_score, cross_val_predict,\n",
    "                                     StratifiedKFold, learning_curve)\n",
    "\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score) \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "sns.set(style = 'white' , context = 'notebook', palette = 'deep')\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data Sets<a class=\"anchor\" id=\"2-bullet\"></a>\n",
    "<hr>\n",
    "Using pandas, we now load the dataset. Basically two files, one is for training purpose and other is for testng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'titanic_train.csv' does not exist: b'titanic_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1c058aecb5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the datasets using pandas's read_csv method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# concat these two datasets, this will come handy while processing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'titanic_train.csv' does not exist: b'titanic_train.csv'"
     ]
    }
   ],
   "source": [
    "# load the datasets using pandas's read_csv method\n",
    "train = pd.read_csv('titanic_train.csv')\n",
    "test = pd.read_csv('titanic_test.csv')\n",
    "\n",
    "# concat these two datasets, this will come handy while processing the data\n",
    "dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "# separately store ID of test datasets, \n",
    "# this will be using at the end of the task to predict.\n",
    "TestPassengerID = test['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look Inside <a class=\"anchor\" id=\"3-bullet\"></a>\n",
    "Let's look what we've just loaded. Datasets size, shape, short description and few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the data set\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it has 891 samples with 12 features. That's somewhat big, let's top 5 sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 records\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of each features and quick thoughts:\n",
    "\n",
    "- PassengerId. Unique identification of the passenger. It shouldn't be necessary for the machine learning model.\n",
    "\n",
    "- Survived. Survival (0 = No, 1 = Yes). Binary variable that will be our target variable.\n",
    "- Pclass. Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd). Ready to go.\n",
    "- Name. Name of the passenger. We need to parse before using it.\n",
    "- Sex. Gender Categorical variable that should be encoded. We can use dummy variable to encode it.\n",
    "- Age. Age in years.\n",
    "- SibSp. Siblings / Spouses aboard the Titanic.\n",
    "- Parch. Parents / Children aboard the Titanic.\n",
    "- Ticket. Ticket number. Big mess. \n",
    "- Fare. Passenger fare.\n",
    "- Cabin. Cabin number.\n",
    "- Embarked. Port of Embarkation , C = Cherbourg, Q = Queenstown, S = Southampton. Categorical feature that should be encoded. We can use feature mapping or make dummy vairables for it.\n",
    "\n",
    "The main conclusion is that we already have a set of features that we can easily use in our machine learning model. But features like Name, Ticket, Cabin require an additional effort before we can integrate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using info method we can get quick overview of the data sets\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One things to notice, we have 891 samples or entries but columns like **Age**, **Cabin** and **Embarked** have some missing values. We can't ignore those. However, let's generate the descriptive statistics to get the basic quantitative information about the features of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three aspects that usually catch my attention when I analyse descriptive statistics:\n",
    "\n",
    "- **Min and max values**: This can give us an idea about the range of values and is helpful to detect outliers.\n",
    "\n",
    "- **Mean and standard deviation**: The mean shows us the central tendency of the distribution, while the standard deviation quantifies its amount of variation.\n",
    "- **Count**: Give us a first perception about the volume of missing data. \n",
    "\n",
    "\n",
    "Let's define a function for missing data analysis more in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for missing data analysis\n",
    "def find_missing_data(data):\n",
    "    Total = data.isnull().sum().sort_values(ascending = False)\n",
    "    Percentage = (data.isnull().sum()/data.isnull().count()).sort_values(ascending = False)\n",
    "    \n",
    "    return pd.concat([Total,Percentage] , axis = 1 , keys = ['Total' , 'Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a heatmap plot to visualize the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking only train set - visualize\n",
    "sns.heatmap(train.isnull(), cbar = False , \n",
    "            yticklabels = False , cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, Cabin feature has terrible amount of missing values, around 77% data are missing. Until now, we only see train datasets, now let's see amount of missing values in whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking only datasets set\n",
    "sns.heatmap(dataset.isnull(), cbar = False , \n",
    "            yticklabels = False , cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it mentioned earlier, ground truth of test datasets are missing.\n",
    "\n",
    "## Problem Spaces <a class=\"anchor\" id=\"4-bullet\"></a>\n",
    "\n",
    "So, we've this train data set and with a quick analysis we've seen its internal components and find some missing values there. We've also seen many observations with concern attributes. \n",
    "\n",
    "**Task**: The goal is to predict the survival or the death of a given passenger based on a set of variables describing their such as age, sex, or passenger class on the boat.\n",
    "\n",
    "So, **Survived** is our **target variable**, This is the variable we're going to predict. `1` represent **survived** , `0` represent **not survived**. And rest of the attributes are called **feature variables**, based on those we need to build a model which will predict whether a passenger survived or not.\n",
    "\n",
    "\n",
    "### Preprocessing\n",
    "In Data Science or ML contexts, Data Preprocessing means to make the Data usable or clean before using it, like before fit the model.\n",
    "\n",
    "Now, the real world data is so messy, they're like -\n",
    "* inconsistant\n",
    "* duplicate records\n",
    "* missing values\n",
    "* invalid data\n",
    "* outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis <a class=\"anchor\" id=\"5-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "### Outlier Detection <a class=\"anchor\" id=\"6-bullet\"></a>\n",
    "\n",
    "There are many method to detect outlier. We will use [Tukey Method](http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/) to accomplish it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        \n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        \n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        \n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | \n",
    "                              (df[col] > Q3 + outlier_step )].index\n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "   \n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)  \n",
    "\n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the outliers rows\n",
    "train.loc[Outliers_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
    "\n",
    "# after removing outlier, let's re-concat the data sets\n",
    "dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed outlier, let's analysis the various features and in the same time we'll also handle the missing value during analysis.\n",
    "\n",
    "- Numerical Analysis\n",
    "- Categorical Analysi\n",
    "\n",
    "# Numerical Analysis  <a class=\"anchor\" id=\"7-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "At first let's analysis the correlation of 'Survived' features with the other numerical features like 'SibSp', 'Parch', 'Age', 'Fare'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \n",
    "corr_numeric = sns.heatmap(dataset[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),\n",
    "                           annot=True, fmt = \".2f\", cmap = \"summer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Fare feature seems to have a significative correlation with the survival probability.\n",
    "\n",
    "But it doesn't make other features useless. Subpopulations in these features can be correlated with the survival. To estimate this, we need to explore in detail these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n",
    "\n",
    "Let's first look the age distribution among survived and not survived passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the Age vs Survived features\n",
    "age_survived = sns.FacetGrid(dataset, col='Survived')\n",
    "age_survived = age_survived.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, It's look like age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived. So, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n",
    "\n",
    "It seems that very young passengers have more chance to survive. Let's look one for time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.FacetGrid(dataset, hue = 'Survived', aspect = 4)\n",
    "fig.map(sns.kdeplot, 'Age' , shade = True)\n",
    "fig.set(xlim = (0, dataset['Age'].max()))\n",
    "fig.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see that aged passengers between 65-80 have less survived.\n",
    "\n",
    "\n",
    "## Missing Age Value\n",
    "\n",
    "We have seen significantly missing values in **Age** coloumn. Missing Age value is a big issue, to address this problem, I've looked at the most correlated features with Age. Let's first try to find correlation between Age and Sex features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize this using box plot\n",
    "AS = sns.factorplot(y=\"Age\", x=\"Sex\", data = dataset, kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age distribution seems to be almost same in Male and Female subpopulations, so Sex is not informative to predict Age. Let's explore `age` and `pclass` distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "facet = sns.FacetGrid(dataset, hue=\"Pclass\", aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see there're more young people from class 3. First class passenger seems more aged than second class and third class are following. But we can't get any information to predict age. But let's try an another approach to visualize with the same parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using boxplot \n",
    "PA = sns.factorplot(data = dataset , x = 'Pclass' , y = 'Age', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can get some information, First class passengers are older than 2nd class passengers who are also older than 3rd class passengers. We can easily visaulize that roughly `37, 29, 24` respectively are the median values of each classes. The strategy can be used to fill Age with the median age of similar rows according to Pclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a custom function for age imputation\n",
    "def AgeImpute(df):\n",
    "    Age = df[0]\n",
    "    Pclass = df[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        if Pclass == 1: return 37\n",
    "        elif Pclass == 2: return 29\n",
    "        else: return 24\n",
    "    else:\n",
    "        return Age\n",
    "\n",
    "# Age Impute\n",
    "dataset['Age'] = dataset[['Age' , 'Pclass']].apply(AgeImpute, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age featured imputed; no missing age records\n",
    "sns.heatmap(dataset.isnull(), yticklabels = False, cbar = False, cmap = 'summer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fare` feature missing some values. However, we will handle it later.\n",
    "\n",
    "## SibSP\n",
    "Now, let's look `Survived` and `SibSp` features in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore SibSp feature vs Survived\n",
    "# We'll use factorplot to analysis\n",
    "Sib_Sur = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train,\n",
    "                   kind=\"bar\", size = 6 , palette = \"Blues\")\n",
    "\n",
    "Sib_Sur.despine(left=True)\n",
    "Sib_Sur = Sib_Sur.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that passengers having a lot of siblings/spouses have less chance to survive.\n",
    "Single passengers (0 SibSP) or with two other persons (SibSP 1 or 2) have more chance to survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parch\n",
    "Let's look `Survived` and `Parch` features in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Parch feature vs Survived\n",
    "# We'll use factorplot to analysis\n",
    "Sur_Par = sns.factorplot(x=\"Parch\",y=\"Survived\",data=train, \n",
    "                         kind=\"bar\", size = 6 , palette = \"GnBu_d\")\n",
    "\n",
    "Sur_Par.despine(left=True)\n",
    "Sur_Par = Sur_Par.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small families have more chance to survive, more than single."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare\n",
    "Let's look `Survived` and `Fare` features in details. We have seen that, Fare feature also mssing some values. Let's handle it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Fare\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have one missing value , I liket to fill it with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical values  <a class=\"anchor\" id=\"8-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "We can turn categorical values into numerical values. This is simply needed because of feeding the traing data to model. We can use feature mapping or create dummy variables.\n",
    "\n",
    "## sex\n",
    "Let's take a quick look of values in this features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['Sex'].head()) # top 5\n",
    "print(' ')\n",
    "print(dataset['Sex'].tail()) # last 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Model can not take such values. We need to map the `sex` column to numeric values, so that our model can digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Sex into categorical value 0 for male and 1 for female\n",
    "sex = pd.get_dummies(dataset['Sex'], drop_first = True)\n",
    "dataset = pd.concat([dataset,sex], axis = 1)\n",
    "\n",
    "# After now, we really don't need to Sex features, we can drop it.\n",
    "dataset.drop(['Sex'] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how much people `survived` based on their `gender`. We can guess though, `Female` passenger survived more than `Male`, this is just assumption though. In the movie, we heard that **Women and Children First**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using countplot to estimate amount\n",
    "sns.countplot(data = train , x = 'Survived' , hue = 'Sex', palette = 'GnBu_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the percentage\n",
    "train[[\"Sex\",\"Survived\"]].groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly obvious that Male have less chance to survive than Female. This is heavily an important feature for our prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pclass\n",
    "Let's explore passenger calsses feature with age feature. From this we can know, how much children, young and aged people were in different passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Pclass\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see there're more young people from class 3. And more aged passenger were in first class, and that indicate that they're rich. So, most of the young people were in class three.\n",
    "\n",
    "However, let's explore the `Pclass` vs `Survived` using `Sex` feature. This will give more information about the survival probability of each classes according to their gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Survived_Pcalss = sns.factorplot(x=\"Pclass\", y=\"Survived\", \n",
    "                                 hue=\"Sex\", data=train,size=6, \n",
    "                                 kind=\"bar\", palette=\"BuGn_r\")\n",
    "Survived_Pcalss.despine(left=True)\n",
    "Survived_Pcalss = Survived_Pcalss.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The passenger survival is not the same in the all classes. First class passengers have more chance to survive than second class and third class passengers. And Female survived more than Male in every classes.\n",
    "\n",
    "## Embarked\n",
    "<hr>\n",
    "Port of Embarkation , C = Cherbourg, Q = Queenstown, S = Southampton. Categorical feature that should be encoded. We can use feature mapping or make dummy vairables for it.\n",
    "\n",
    "However, let's explore it combining `Pclass` and `Survivied` features. So that, we can get idea about the classes of passengers and also the concern embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Embarked' vs 'Survived'\n",
    "sns.barplot(dataset['Embarked'], dataset['Survived']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like, coming from Cherbourg people have more chance to survive. But why? That's weird. Let's compare this feature with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count\n",
    "print(dataset.groupby(['Embarked'])['PassengerId'].count())\n",
    "\n",
    "# Compare with other variables\n",
    "dataset.groupby(['Embarked']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, C passenger have paid more and travelling in a better class than people embarking on Q and S. Amount of passenger from S is larger than others. But survival probability of C have more than others. \n",
    "\n",
    "As we've seen earlier that Embarked feature also has some missing values, so we can fill them with the most fequent value of Embarked which is S (almost 904)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missing values\n",
    "print(dataset[\"Embarked\"].isnull().sum())\n",
    "\n",
    "# Fill Embarked nan values of dataset set with 'S' most frequent value\n",
    "dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize it to confirm\n",
    "sns.heatmap(dataset.isnull(), yticklabels = False, \n",
    "            cbar = False, cmap = 'summer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it goes. Now, there's no missing values in Embarked feature. Let's explore this feature a little bit more. We can viz the survival probability with the amount of classes passenger embarked on different port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting passenger based on Pclass and Embarked \n",
    "Embarked_Pc = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=dataset,\n",
    "                   size=5, kind=\"count\", palette=\"muted\", hue = 'Survived')\n",
    "\n",
    "Embarked_Pc.despine(left=True)\n",
    "Embarked_Pc = Embarked_Pc.set_ylabels(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the third class is the most frequent for passenger coming from Southampton (S) and Queenstown (Q), and but Cherbourg passengers are mostly in first class. From this, we can also get idea about the economic condition of these region on that time.\n",
    "\n",
    "However, We need to map the `Embarked` column to numeric values, so that our model can digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variable\n",
    "embarked = pd.get_dummies(dataset['Embarked'], drop_first = True)\n",
    "dataset = pd.concat([dataset,embarked], axis = 1)\n",
    "\n",
    "# after now, we don't need Embarked coloumn anymore, so we can drop it.\n",
    "dataset.drop(['Embarked'] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commitment for Feature Analysis\n",
    "So far, we've seen various subpopulation components of each features and fill the gap of missing values. We've done many visualization of each components and tried to find some insight of them. Though we can dive into more deeper but I like to end this here and try to focus on feature engineering. \n",
    "\n",
    "We saw that, we've many messy features like `Name`, `Ticket` and `Cabin`. We can do feature engineering to each of them and find out some meaningfull insight. But, I like to work on only `Name` variables. `Ticket` is, I think not too much important for prediction task and again almost 77% data missing in `Cabin` variables.\n",
    "\n",
    "However, let's have a quick look over our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering <a class=\"anchor\" id=\"9-bullet\"></a>\n",
    "\n",
    "[Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is an informal topic, but it is considered essential in applied machine learning. Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
    "\n",
    "Some resources to get more depth on it -\n",
    "\n",
    "- [Data Preprocessing and Feature Exploration](https://www.youtube.com/watch?v=V0u6bxQOUJ8&t=1384s)\n",
    "- [Makes a Good Feature](https://www.youtube.com/watch?v=N9fDIAflCMY)\n",
    "- [Feature Engineering](https://www.kdnuggets.com/tag/feature-engineering)\n",
    "- [Automated Feature Engineering](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219)\n",
    "\n",
    "Feature engineering is the art of converting raw data into useful features. There are several feature engineering techniques that you can apply. Some techniques are -\n",
    "\n",
    "- Box-Cox transformations\n",
    "- Polynomials generation through non-linear expansions\n",
    "\n",
    "But we don't wanna be too serious on this rather than simply apply feature engineering approaches to get usefull information.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Name \n",
    "\n",
    "We can assume that people's title influences how they are treated. In our case, we have several titles (like Mr, Mrs, Miss, Master etc ), but only some of them are shared by a significant number of people. Accordingly, it would be interesting if we could group some of the titles and simplify our analysis.\n",
    "\n",
    "Let's analyse the 'Name' and see if we can find a sensible way to group them. Then, we test our new groups and, if it works in an acceptable way, we keep it. For now, optimization will not be a goal. The focus is on getting something that can improve our current situation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Title from Name\n",
    "dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n",
    "\n",
    "# add dataset_title to the main dataset named 'Title'\n",
    "dataset[\"Title\"] = pd.Series(dataset_title)\n",
    "\n",
    "# count\n",
    "dataset[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plot (titles and Age)\n",
    "plt.figure(figsize=(18,5))\n",
    "sns.barplot(x=dataset['Title'], y = dataset['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means per title\n",
    "print(dataset.groupby('Title')['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 18 titles in the dataset and most of them are very uncommon so we like to group them in 4 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to categorical values Title \n",
    "dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess',\n",
    "                                             'Capt', 'Col','Don', 'Dr', \n",
    "                                             'Major', 'Rev', 'Sir', 'Jonkheer',\n",
    "                                             'Dona'], 'Rare')\n",
    "\n",
    "dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 ,\n",
    "                                         \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \n",
    "                                         \"Rare\":3})\n",
    "\n",
    "dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n",
    "\n",
    "# Drop Name variable\n",
    "dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz counts the title coloumn\n",
    "sns.countplot(dataset[\"Title\"]).set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see, based on title what's the survival probability\n",
    "sns.barplot(x='Title', y='Survived', data=dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catching Aspects:\n",
    "\n",
    "- People with the title 'Mr' survived less than people with any other title.\n",
    "- Titles with a survival rate higher than 70% are those that correspond to female (Miss-Mrs)\n",
    "\n",
    "Our new category, 'Rare', should be more discretized. As we can see by the error bar (black line), there is a significant uncertainty around the mean value. Probably, one of the problems is that we are mixing male and female titles in the 'Rare' category. We should proceed with a more detailed analysis to sort this out. Also, the category 'Master' seems to have a similar problem. For now, we will not make any changes, but we will keep these two situations in our mind for future improvement of our data set.\n",
    "\n",
    "\n",
    "From now on, there's no Name features and have Title feature to represent it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz top 5\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Family size\n",
    "\n",
    "I like to create a `Famize` feature which is the sum of `SibSp` , `Parch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a family size descriptor from SibSp and Parch\n",
    "dataset[\"Famize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n",
    "\n",
    "# Drop SibSp and Parch variables\n",
    "dataset.drop(labels = [\"SibSp\",'Parch'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz the survival probabily of Famize feature\n",
    "\n",
    "facet = sns.FacetGrid(dataset, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Famize',shade= True)\n",
    "facet.set(xlim=(0, dataset['Famize'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival probability is worst for large families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin & Ticket\n",
    "Now, `Cabin` feature has a huge data missing. So, I like to drop it anyway. Moreover, we also can't get to much information by `Ticket` feature for prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some useless features\n",
    "dataset.drop(labels = [\"Ticket\",'Cabin','PassengerId'], axis = 1, \n",
    "             inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling <a class=\"anchor\" id=\"10-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "Here, we split our datasets according to the previous amounts and make test and train set. To avoid overfitting event we can create validation set but that's not effective. So, we use [**K-Fold**](http://scikit-learn.org/stable/modules/cross_validation.html#k-fold) approaches and use [**StratifiedKFold**](http://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold) to split the train datasets into 10 (by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train dataset and test dataset\n",
    "train = dataset[:len(train)]\n",
    "test = dataset[len(train):]\n",
    "test.drop(labels=[\"Survived\"],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate train features and label \n",
    "Y_train = train[\"Survived\"].astype(int)\n",
    "X_train = train.drop(labels = [\"Survived\"],axis = 1)\n",
    "\n",
    "# Cross validate model with Kfold stratified cross val\n",
    "K_fold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier <a class=\"anchor\" id=\"11-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "I compared 10 popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure.\n",
    "\n",
    "- KNN\n",
    "- AdaBoost\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Support Vector Machine\n",
    "- Gradient Boosting\n",
    "- Logistic regression\n",
    "- Linear Discriminant Analysis\n",
    "- Multiple layer perceprton\n",
    "\n",
    "## Evaluation using Cross Validation\n",
    "A great alternative is to use Scikit-Learn's `cross-validation` feature. The following performs **K-fold** cross validation; it randomly splits the training set into 10 distinct subsets called folds, then it trains and evaluates the Models 10 times, picking a different fold for evaluation every time and training on the other 9 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling step Test differents algorithms \n",
    "random_state = 2\n",
    "\n",
    "models = [] # append all models or predictive models \n",
    "cv_results = [] # cross validation result\n",
    "cv_means = [] # cross validation mean value\n",
    "cv_std = [] # cross validation standard deviation\n",
    "\n",
    "models.append(KNeighborsClassifier())\n",
    "models.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "models.append(DecisionTreeClassifier(random_state=random_state))\n",
    "models.append(RandomForestClassifier(random_state=random_state))\n",
    "models.append(ExtraTreesClassifier(random_state=random_state))\n",
    "models.append(SVC(random_state=random_state))\n",
    "models.append(GradientBoostingClassifier(random_state=random_state))\n",
    "models.append(LogisticRegression(random_state = random_state))\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(MLPClassifier(random_state=random_state))\n",
    "\n",
    "\n",
    "for model in models :\n",
    "    cv_results.append(cross_val_score(model, X_train, Y_train, \n",
    "                                      scoring = \"accuracy\", cv = K_fold, n_jobs=4))\n",
    "\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"CrossValMeans\":cv_means,\n",
    "        \"CrossValErrors\": cv_std,\n",
    "        \"Algorithms\":[\n",
    "                     \"KNeighboors\",\n",
    "                     \"AdaBoost\", \n",
    "                     \"DecisionTree\",   \n",
    "                     \"RandomForest\",\n",
    "                     \"ExtraTrees\",\n",
    "                     \"SVC\",\n",
    "                     \"GradientBoosting\",                      \n",
    "                     \"LogisticRegression\",\n",
    "                     \"LinearDiscriminantAnalysis\",\n",
    "                     \"MultipleLayerPerceptron\"]\n",
    "    })\n",
    "\n",
    "cv_plot = sns.barplot(\"CrossValMeans\",\"Algorithms\", data = cv_frame,\n",
    "                palette=\"husl\", orient = \"h\", **{'xerr':cv_std})\n",
    "\n",
    "cv_plot.set_xlabel(\"Mean Accuracy\")\n",
    "cv_plot = cv_plot.set_title(\"CV Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore following models separately:\n",
    "\n",
    "- GBC Classifier\n",
    "- Linear Discriminant Analysis \n",
    "- Logistic Regression\n",
    "- Random Forest Classifer\n",
    "- Gaussian Naive Bayes\n",
    "- Support Vectore Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBC Classifier\n",
    "GBC_Model = GradientBoostingClassifier()\n",
    "\n",
    "scores = cross_val_score(GBC_Model, X_train, Y_train, cv = K_fold,\n",
    "                       n_jobs = 4, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis \n",
    "LDA_Model= LinearDiscriminantAnalysis()\n",
    "\n",
    "scores = cross_val_score(LDA_Model, X_train, Y_train, cv = K_fold,\n",
    "                       n_jobs = 4, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "#\n",
    "Log_Model = LogisticRegression(C=1)\n",
    "scores = cross_val_score(Log_Model, X_train, Y_train, cv=K_fold, \n",
    "                        n_jobs=4, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier Model\n",
    "#\n",
    "RFC_model = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(RFC_model, X_train, Y_train, cv=K_fold, \n",
    "                        n_jobs=4, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "GNB_Model = GaussianNB()\n",
    "\n",
    "scores = cross_val_score(GNB_Model, X_train, Y_train, cv=K_fold, \n",
    "                        n_jobs=4, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "SVM_Model = SVC()\n",
    "\n",
    "scores = cross_val_score(SVM_Model, X_train, Y_train, cv=K_fold, \n",
    "                        n_jobs=4, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning <a class=\"anchor\" id=\"12-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "I decided to choose this promising models of GradientBoosting, Linear Discriminant Analysis, RandomForest, Logistic Regression and SVM for the ensemble modeling. So, now we need to fine-tune them.\n",
    "\n",
    "One way to do that would be to fiddle with the hyperparameters manually until we find a great combination of hyperparamerter values. This would be very tedious work, and we may not have time to explore many combination. Instead we should get `Scikit-Learn's GridSearchCV` to search for us. All we need to do is tell it which hyperparameters we want it to experiment with, and what values to try out and it will evaluate all the possible combination of hyperparameter values, using **cross-validation**.\n",
    "\n",
    "Here we perform grid search optimization for GradientBoosting, RandomForest,  Linear Discriminant Analysis, Logistic Regression and SVC classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting tunning\n",
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {\n",
    "              'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "              'max_depth': [4, 8,16],\n",
    "              'min_samples_leaf': [100,150,250],\n",
    "              'max_features': [0.3, 0.1]\n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC, param_grid = gb_param_grid, cv=K_fold, \n",
    "                     scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsGBC.fit(X_train,Y_train)\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"min_samples_split\": [2, 6, 20],\n",
    "              \"min_samples_leaf\": [1, 4, 16],\n",
    "              \"n_estimators\" :[100,200,300,400],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC, param_grid = rf_param_grid, cv=K_fold,\n",
    "                     scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train,Y_train)\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression Parameters tunning \n",
    "LRM = LogisticRegression()\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "lr_param_grid = {\"penalty\" : [\"l2\"],\n",
    "              \"tol\" : [0.0001,0.0002,0.0003],\n",
    "              \"max_iter\": [100,200,300],\n",
    "              \"C\" :[0.01, 0.1, 1, 10, 100],\n",
    "              \"intercept_scaling\": [1, 2, 3, 4],\n",
    "              \"solver\":['liblinear'],\n",
    "              \"verbose\":[1]}\n",
    "\n",
    "\n",
    "gsLRM = GridSearchCV(LRM, param_grid = lr_param_grid, cv=K_fold,\n",
    "                     scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsLRM.fit(X_train,Y_train)\n",
    "LRM_best = gsLRM.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsLRM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis - Parameter Tuning\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "lda_param_grid = {\"solver\" : [\"svd\"],\n",
    "              \"tol\" : [0.0001,0.0002,0.0003]}\n",
    "\n",
    "\n",
    "gsLDA = GridSearchCV(LDA, param_grid = lda_param_grid, cv=K_fold,\n",
    "                     scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsLDA.fit(X_train,Y_train)\n",
    "LDA_best = gsLDA.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsLDA.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVC classifier\n",
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel': ['rbf'], \n",
    "                  'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100, 200, 300]}\n",
    "\n",
    "gsSVMC = GridSearchCV(SVMC, param_grid = svc_param_grid, cv = K_fold,\n",
    "                      scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(X_train,Y_train)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Plot Learning Curves <a class=\"anchor\" id=\"13-bullet\"></a>\n",
    "**Diagnose Bias and Variance to Reduce Error**\n",
    "<hr>\n",
    "Learning curves are a good way to see the overfitting and underfitting effect on the training set and the effect of the training size on the accuracy. Learning curves plots the model's performance on the training set and the validation set as a function of training set size. To generate the plots, we simply train the model several times on different sized subsets of the training sets. In a nutshell, a learning curves shows how error changes as the training set size increases.\n",
    "\n",
    "If a models perform well on the training data but generalizes poorly according to the cross-validation metrics, the model is called overfitting. And again if it performs poorly on both, the model is called underfitting.\n",
    "\n",
    "When the model is trained on very few training instances, it is incapable of generalizing properly, which is why the validation error will be initially quite big.\n",
    "\n",
    "> **Underfitting**: If model is underfitting the training data, adding more training example will not help. We need to use more complex model or come up with better features.\n",
    "\n",
    "> **Overfitting**: One way to improve the overfitting model is to feed it more training data until the validation error reaches the training error.\n",
    "\n",
    "**Resource**\n",
    "- [Learning Curves for Machine Learning](https://www.dataquest.io/blog/learning-curves-machine-learning/)\n",
    "\n",
    "\n",
    "## Bias-Variance Trade-Off\n",
    "<hr>\n",
    "A model's generalization error can be expressed as the sum of three very different errors.\n",
    "\n",
    "- Bias\n",
    "- Variance\n",
    "- Irreducible Error\n",
    "\n",
    "#### Bias Error in Learning Curve\n",
    "This part of generalization error is due to the wrong assumption, such as assuming that, the data is linear when it is actually quadratic.\n",
    "\n",
    "- **A high bias model is most likely to underfit the training data**\n",
    "\n",
    "\n",
    "#### Variance Error in Learning Curve\n",
    "This part of generalization is due to the model is excessive sensitivity to small variations in the training data.\n",
    "\n",
    "- **A high variance model is most likely to overfit the training data**\n",
    "\n",
    "#### Irreducible Error in Learning Curve\n",
    "This is due to the noisiness of the data itself. This is not concern now, because we already clean the data sets.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Increasing a model's complexity will typically increases its variance and reduce its bias. Conversly, reducing a model's complexity increases its bias and reduces its variance.\n",
    "\n",
    "\n",
    "Now, we'll define a learning curve ploting function where `x` and `y` axies will be traning set size and scores (not errors) gradually. So the higher the score, the better the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting - Learning Curve \n",
    "plot_learning_curve(estimator = gsGBC.best_estimator_,title = \"GBC learning curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - Learning Curve\n",
    "plot_learning_curve(estimator = gsRFC.best_estimator_ ,title = \"RF learninc curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - Learning Curve    gsLRM.best_estimator_\n",
    "plot_learning_curve(estimator = Log_Model ,title = \"Logistic Regression - Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis - Learning Curve\n",
    "plot_learning_curve(estimator = gsLDA.best_estimator_ ,title = \"Linear Discriminant - Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine - Learning Curve\n",
    "plot_learning_curve(estimator = gsSVMC.best_estimator_,title = \"SVC learning curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC seem to better generalize the prediction since the training and cross-validation curves are close together. And again Random Forest and GradientBoosting classifiers tend to overfit the training set. One way to improve the overfitting model is to feed it more training data until the validation error reaches the training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble modeling <a class=\"anchor\" id=\"14-bullet\"></a>\n",
    "<hr>\n",
    "\n",
    "The another way to fine-tune our system is to try to combine the models that perform best. The goup will often perform better than the best individual model, especially if the individual models make very different types of errors.\n",
    "\n",
    "Building a model on top of many other models are called Ensemble Learning. And it is often a great way to push ML algorithm even further.\n",
    "\n",
    "I used **voting classifier** to combine the predictions coming from the 5 classifiers. I preferred to pass the argument `soft` to the voting parameter to take into account the probability of each vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#about 84%\n",
    "VotingPredictor = VotingClassifier(estimators =\n",
    "                           [('rfc', RFC_best), \n",
    "                            ('gbc', GBC_best),\n",
    "                           ('svc', SVMC_best)],\n",
    "                           voting='soft', n_jobs = 4)\n",
    "\n",
    "# 82.97%\n",
    "# VotingPredictor = VotingClassifier(estimators =\n",
    "#                            [ ('rfc', RFC_best), \n",
    "#                             ('svc', SVMC_best),\n",
    "#                             ('gbc', GBC_best),\n",
    "#                             ('lda', LDA_best),\n",
    "#                             ('lrm', LRM_best)],\n",
    "#                            voting='soft', n_jobs = 4)\n",
    "\n",
    "VotingPredictor = VotingPredictor.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(VotingPredictor, X_train, Y_train, cv = K_fold,\n",
    "                       n_jobs = 4, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Predictor - Learning Curve\n",
    "plot_learning_curve(estimator = VotingPredictor, title = \"VP learning curve\",\n",
    "                    X = X_train, y = Y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictor  <a class=\"anchor\" id=\"15-bullet\"></a>\n",
    "**Kaggle : Titanic Competition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictive_Model = pd.DataFrame({\n",
    "        \"PassengerId\": TestPassengerID,\n",
    "        \"Survived\": VotingPredictor.predict(test)})\n",
    "\n",
    "Predictive_Model.to_csv('titanic_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look inside\n",
    "submission = pd.read_csv('titanic_model.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V3 change Voting Predictor (rfc, gbc, svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
